{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af523c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79890c3e-2d03-4712-bc22-a00340e82dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/03 07:27:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d516f04-be00-4f09-a7fe-702cd7ac0fff",
   "metadata": {},
   "source": [
    "Setup Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55d28f6d-3977-4a83-8b45-e6188908f71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_train_date': datetime.datetime(2009, 1, 1, 0, 0),\n",
      " 'model_train_date_str': '2009-01-01',\n",
      " 'oot_end_date': datetime.datetime(2008, 12, 31, 0, 0),\n",
      " 'oot_period_months': 12,\n",
      " 'oot_start_date': datetime.datetime(2008, 1, 1, 0, 0),\n",
      " 'train_test_end_date': datetime.datetime(2007, 12, 31, 0, 0),\n",
      " 'train_test_period_months': 108,\n",
      " 'train_test_ratio': 0.8,\n",
      " 'train_test_start_date': datetime.datetime(1999, 1, 1, 0, 0)}\n"
     ]
    }
   ],
   "source": [
    "# set up config\n",
    "model_train_date_str = \"2009-01-01\"\n",
    "train_test_period_months = 108\n",
    "oot_period_months = 12\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "config = {}\n",
    "config[\"model_train_date_str\"] = model_train_date_str\n",
    "config[\"train_test_period_months\"] = train_test_period_months\n",
    "config[\"oot_period_months\"] =  oot_period_months\n",
    "config[\"model_train_date\"] =  datetime.strptime(model_train_date_str, \"%Y-%m-%d\")\n",
    "config[\"oot_end_date\"] = config[\"model_train_date\"] - timedelta(days = 1)\n",
    "config[\"oot_start_date\"] =  config['model_train_date'] - relativedelta(months = oot_period_months)\n",
    "config[\"train_test_end_date\"] =  config[\"oot_start_date\"] - timedelta(days = 1)\n",
    "config[\"train_test_start_date\"] =  config[\"oot_start_date\"] - relativedelta(months = train_test_period_months)\n",
    "config[\"train_test_ratio\"] = train_test_ratio \n",
    "\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c05a50d-24d5-429c-9908-01f79eb305d5",
   "metadata": {},
   "source": [
    "Label Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b66ff91-4999-41b6-9085-0667fcea83f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 120 parquet directories with Spark...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label store count: 101766\n",
      "root\n",
      " |-- encounter_id: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "+------------+-----+-------------+\n",
      "|encounter_id|label|snapshot_date|\n",
      "+------------+-----+-------------+\n",
      "|     4679262|    0|   2000-08-01|\n",
      "|     4680186|    0|   2000-08-02|\n",
      "|     4682388|    0|   2000-08-03|\n",
      "|     4728330|    0|   2000-08-04|\n",
      "|     4729674|    0|   2000-08-05|\n",
      "+------------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# connect to label store - use Spark\n",
    "# read all parquet directories\n",
    "label_store_path = \"datamart/gold/label_store/\"\n",
    "parquet_dirs = [os.path.join(label_store_path, d) for d in os.listdir(label_store_path) \n",
    "                if d.endswith('.parquet')]\n",
    "\n",
    "print(f\"Reading {len(parquet_dirs)} parquet directories with Spark...\")\n",
    "\n",
    "# read all parquet files using Spark\n",
    "label_store_sdf = spark.read.parquet(*parquet_dirs)\n",
    "\n",
    "print(f\"Label store count: {label_store_sdf.count()}\")\n",
    "label_store_sdf.printSchema()\n",
    "label_store_sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "792cbe1e-1dd5-44cb-b844-4691d6552e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                        (0 + 12) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered labels: 101766 records\n",
      "Date range: 1999-01-01 00:00:00 to 2008-12-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# filter labels by date range using Spark\n",
    "labels_sdf = label_store_sdf.filter(\n",
    "    (col(\"snapshot_date\") >= config[\"train_test_start_date\"]) & \n",
    "    (col(\"snapshot_date\") <= config[\"oot_end_date\"])\n",
    ")\n",
    "\n",
    "print(f\"Filtered labels: {labels_sdf.count()} records\")\n",
    "print(f\"Date range: {config['train_test_start_date']} to {config['oot_end_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d610d34-e975-47eb-9529-40726cc38476",
   "metadata": {},
   "source": [
    "Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50799232-ba5b-461f-bb40-e2e24a85ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 120 parquet directories with Spark...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature store count: 101766\n",
      "root\n",
      " |-- encounter_id: integer (nullable = true)\n",
      " |-- race_AfricanAmerican: integer (nullable = true)\n",
      " |-- race_Caucasian: integer (nullable = true)\n",
      " |-- race_Asian: integer (nullable = true)\n",
      " |-- race_Hispanic: integer (nullable = true)\n",
      " |-- is_female: integer (nullable = true)\n",
      " |-- age_midpoint: integer (nullable = true)\n",
      " |-- admission_severity_score: integer (nullable = true)\n",
      " |-- admission_source_risk_score: integer (nullable = true)\n",
      " |-- poor_glucose_control: integer (nullable = true)\n",
      " |-- metformin_ord: integer (nullable = true)\n",
      " |-- insulin_ord: integer (nullable = true)\n",
      " |-- diabetesMed: integer (nullable = true)\n",
      " |-- severity_x_visits: integer (nullable = true)\n",
      " |-- medication_density: double (nullable = true)\n",
      " |-- diag_1_ord: integer (nullable = true)\n",
      " |-- diag_2_ord: integer (nullable = true)\n",
      " |-- diag_3_ord: integer (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "+------------+--------------------+--------------+----------+-------------+---------+------------+------------------------+---------------------------+--------------------+-------------+-----------+-----------+-----------------+--------------------+----------+----------+----------+-------------+\n",
      "|encounter_id|race_AfricanAmerican|race_Caucasian|race_Asian|race_Hispanic|is_female|age_midpoint|admission_severity_score|admission_source_risk_score|poor_glucose_control|metformin_ord|insulin_ord|diabetesMed|severity_x_visits|  medication_density|diag_1_ord|diag_2_ord|diag_3_ord|snapshot_date|\n",
      "+------------+--------------------+--------------+----------+-------------+---------+------------+------------------------+---------------------------+--------------------+-------------+-----------+-----------+-----------------+--------------------+----------+----------+----------+-------------+\n",
      "|    15758256|                   0|             0|         1|            0|        0|          65|                       1|                          1|                   0|            0|          1|          1|                0|0.024144870943280904|         5|         5|         0|   2005-08-01|\n",
      "|    15765702|                   1|             0|         0|            0|        1|          25|                       2|                          1|                   0|            0|          1|          1|                2| 0.00746965455630469|         2|         8|        10|   2005-08-02|\n",
      "|    15774312|                   0|             1|         0|            0|        0|          75|                       2|                          1|                   0|            0|          1|          1|                0| 0.02105263214857623|         0|         0|         0|   2005-08-03|\n",
      "|    15779280|                   0|             1|         0|            0|        0|          65|                       2|                          1|                   0|            1|          1|          1|                2|0.059340660443859924|         0|         0|         0|   2005-08-04|\n",
      "|    15784284|                   0|             1|         0|            0|        1|          55|                       0|                          0|                   0|            0|          0|          1|                0| 0.02542373039314239|         7|        10|         7|   2005-08-05|\n",
      "+------------+--------------------+--------------+----------+-------------+---------+------------+------------------------+---------------------------+--------------------+-------------+-----------+-----------+-----------------+--------------------+----------+----------+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# connect to feature store - use Spark\n",
    "feature_store_path = \"datamart/gold/feature_store/\"\n",
    "parquet_dirs = [os.path.join(feature_store_path, d) for d in os.listdir(feature_store_path) \n",
    "                if d.endswith('.parquet')]\n",
    "\n",
    "print(f\"Reading {len(parquet_dirs)} parquet directories with Spark...\")\n",
    "\n",
    "# read all parquet files using Spark\n",
    "features_store_sdf = spark.read.parquet(*parquet_dirs)\n",
    "\n",
    "print(f\"Feature store count: {features_store_sdf.count()}\")\n",
    "features_store_sdf.printSchema()\n",
    "features_store_sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7cdc2a8-d7fe-4a75-b270-3c808dba3c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                       (0 + 12) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered features: 101766 records\n",
      "Date range: 1999-01-01 00:00:00 to 2008-12-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# filter features by date range using Spark\n",
    "features_sdf = features_store_sdf.filter(\n",
    "    (col(\"snapshot_date\") >= config[\"train_test_start_date\"]) & \n",
    "    (col(\"snapshot_date\") <= config[\"oot_end_date\"])\n",
    ")\n",
    "\n",
    "print(f\"Filtered features: {features_sdf.count()} records\")\n",
    "print(f\"Date range: {config['train_test_start_date']} to {config['oot_end_date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29be3eec-a660-4b95-b004-731821cdc699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined data count: encounter_id                   101766\n",
      "snapshot_date                  101766\n",
      "label                          101766\n",
      "race_AfricanAmerican           101766\n",
      "race_Caucasian                 101766\n",
      "race_Asian                     101766\n",
      "race_Hispanic                  101766\n",
      "is_female                      101766\n",
      "age_midpoint                   101766\n",
      "admission_severity_score       101766\n",
      "admission_source_risk_score    101766\n",
      "poor_glucose_control           101766\n",
      "metformin_ord                  101766\n",
      "insulin_ord                    101766\n",
      "diabetesMed                    101766\n",
      "severity_x_visits              101766\n",
      "medication_density             101766\n",
      "diag_1_ord                     101766\n",
      "diag_2_ord                     101766\n",
      "diag_3_ord                     101766\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>label</th>\n",
       "      <th>race_AfricanAmerican</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>is_female</th>\n",
       "      <th>age_midpoint</th>\n",
       "      <th>admission_severity_score</th>\n",
       "      <th>admission_source_risk_score</th>\n",
       "      <th>poor_glucose_control</th>\n",
       "      <th>metformin_ord</th>\n",
       "      <th>insulin_ord</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>severity_x_visits</th>\n",
       "      <th>medication_density</th>\n",
       "      <th>diag_1_ord</th>\n",
       "      <th>diag_2_ord</th>\n",
       "      <th>diag_3_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15758256</td>\n",
       "      <td>2005-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024145</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15765702</td>\n",
       "      <td>2005-08-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15774312</td>\n",
       "      <td>2005-08-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15779280</td>\n",
       "      <td>2005-08-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15784284</td>\n",
       "      <td>2005-08-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101761</th>\n",
       "      <td>403830632</td>\n",
       "      <td>1999-02-24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101762</th>\n",
       "      <td>403830932</td>\n",
       "      <td>1999-02-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.007826</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101763</th>\n",
       "      <td>403845980</td>\n",
       "      <td>1999-02-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101764</th>\n",
       "      <td>403846202</td>\n",
       "      <td>1999-02-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101765</th>\n",
       "      <td>403857506</td>\n",
       "      <td>1999-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101766 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        encounter_id snapshot_date  label  race_AfricanAmerican  \\\n",
       "0           15758256    2005-08-01      0                     0   \n",
       "1           15765702    2005-08-02      1                     1   \n",
       "2           15774312    2005-08-03      0                     0   \n",
       "3           15779280    2005-08-04      0                     0   \n",
       "4           15784284    2005-08-05      0                     0   \n",
       "...              ...           ...    ...                   ...   \n",
       "101761     403830632    1999-02-24      0                     1   \n",
       "101762     403830932    1999-02-25      0                     0   \n",
       "101763     403845980    1999-02-26      0                     0   \n",
       "101764     403846202    1999-02-27      0                     0   \n",
       "101765     403857506    1999-02-28      0                     0   \n",
       "\n",
       "        race_Caucasian  race_Asian  race_Hispanic  is_female  age_midpoint  \\\n",
       "0                    0           1              0          0            65   \n",
       "1                    0           0              0          1            25   \n",
       "2                    1           0              0          0            75   \n",
       "3                    1           0              0          0            65   \n",
       "4                    1           0              0          1            55   \n",
       "...                ...         ...            ...        ...           ...   \n",
       "101761               0           0              0          0            95   \n",
       "101762               1           0              0          1            25   \n",
       "101763               1           0              0          1            45   \n",
       "101764               1           0              0          0            65   \n",
       "101765               1           0              0          0            85   \n",
       "\n",
       "        admission_severity_score  admission_source_risk_score  \\\n",
       "0                              1                            1   \n",
       "1                              2                            1   \n",
       "2                              2                            1   \n",
       "3                              2                            1   \n",
       "4                              0                            0   \n",
       "...                          ...                          ...   \n",
       "101761                         2                            2   \n",
       "101762                         3                            2   \n",
       "101763                         3                            2   \n",
       "101764                         3                            2   \n",
       "101765                         3                            2   \n",
       "\n",
       "        poor_glucose_control  metformin_ord  insulin_ord  diabetesMed  \\\n",
       "0                          0              0            1            1   \n",
       "1                          0              0            1            1   \n",
       "2                          0              0            1            1   \n",
       "3                          0              1            1            1   \n",
       "4                          0              0            0            1   \n",
       "...                      ...            ...          ...          ...   \n",
       "101761                     0              0            0            1   \n",
       "101762                     0              0            0            0   \n",
       "101763                     0              1            0            1   \n",
       "101764                     1              1            2            1   \n",
       "101765                     0              0            0            0   \n",
       "\n",
       "        severity_x_visits  medication_density  diag_1_ord  diag_2_ord  \\\n",
       "0                       0            0.024145           5           5   \n",
       "1                       2            0.007470           2           8   \n",
       "2                       0            0.021053           0           0   \n",
       "3                       2            0.059341           0           0   \n",
       "4                       0            0.025424           7          10   \n",
       "...                   ...                 ...         ...         ...   \n",
       "101761                  2            0.046154          10          10   \n",
       "101762                  7            0.007826           4           7   \n",
       "101763                  0            0.060606          10           8   \n",
       "101764                  0            0.045455           7           3   \n",
       "101765                  3            0.101010           3          10   \n",
       "\n",
       "        diag_3_ord  \n",
       "0                0  \n",
       "1               10  \n",
       "2                0  \n",
       "3                0  \n",
       "4                7  \n",
       "...            ...  \n",
       "101761          10  \n",
       "101762           0  \n",
       "101763          10  \n",
       "101764           1  \n",
       "101765           7  \n",
       "\n",
       "[101766 rows x 20 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join labels and features using Spark\n",
    "data_sdf = labels_sdf.join(\n",
    "    features_sdf, \n",
    "    on=[\"encounter_id\", \"snapshot_date\"], \n",
    "    how=\"inner\"\n",
    ").toPandas()\n",
    "\n",
    "print(f\"Joined data count: {data_sdf.count()}\")\n",
    "data_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8b6394-7af8-4697-93ee-76bc39d2efb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 73507\n",
      "X_test 18377\n",
      "X_oot 9882\n",
      "y_train 73507 0.11\n",
      "y_test 18377 0.11\n",
      "y_oot 9882 0.11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_AfricanAmerican</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>is_female</th>\n",
       "      <th>age_midpoint</th>\n",
       "      <th>admission_severity_score</th>\n",
       "      <th>admission_source_risk_score</th>\n",
       "      <th>poor_glucose_control</th>\n",
       "      <th>metformin_ord</th>\n",
       "      <th>insulin_ord</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>severity_x_visits</th>\n",
       "      <th>medication_density</th>\n",
       "      <th>diag_1_ord</th>\n",
       "      <th>diag_2_ord</th>\n",
       "      <th>diag_3_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64497</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92020</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58939</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50295</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048682</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101228</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34324</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99464</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37345</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73202</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6862</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73507 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        race_AfricanAmerican  race_Caucasian  race_Asian  race_Hispanic  \\\n",
       "64497                      0               1           0              0   \n",
       "92020                      0               1           0              0   \n",
       "58939                      0               1           0              0   \n",
       "50295                      0               1           0              0   \n",
       "101228                     1               0           0              0   \n",
       "...                      ...             ...         ...            ...   \n",
       "34324                      0               1           0              0   \n",
       "99464                      0               1           0              0   \n",
       "37345                      0               1           0              0   \n",
       "73202                      0               1           0              0   \n",
       "6862                       0               1           0              0   \n",
       "\n",
       "        is_female  age_midpoint  admission_severity_score  \\\n",
       "64497           1            65                         1   \n",
       "92020           0            75                         2   \n",
       "58939           1            45                         3   \n",
       "50295           1            75                         0   \n",
       "101228          1            25                         3   \n",
       "...           ...           ...                       ...   \n",
       "34324           0            85                         3   \n",
       "99464           1            75                         3   \n",
       "37345           1            55                         1   \n",
       "73202           1            45                         3   \n",
       "6862            0            55                         3   \n",
       "\n",
       "        admission_source_risk_score  poor_glucose_control  metformin_ord  \\\n",
       "64497                             1                     0              0   \n",
       "92020                             1                     0              0   \n",
       "58939                             2                     0              0   \n",
       "50295                             0                     0              0   \n",
       "101228                            3                     0              0   \n",
       "...                             ...                   ...            ...   \n",
       "34324                             2                     0              1   \n",
       "99464                             2                     0              0   \n",
       "37345                             3                     0              0   \n",
       "73202                             2                     0              1   \n",
       "6862                              2                     0              0   \n",
       "\n",
       "        insulin_ord  diabetesMed  severity_x_visits  medication_density  \\\n",
       "64497             2            1                  0            0.083333   \n",
       "92020            -1            1                  0            0.086183   \n",
       "58939             0            0                  0            0.064103   \n",
       "50295             0            0                  0            0.048682   \n",
       "101228            1            1                  2            0.013774   \n",
       "...             ...          ...                ...                 ...   \n",
       "34324             0            1                  2            0.034615   \n",
       "99464             0            0                  0            0.150000   \n",
       "37345             0            0                  0            0.026637   \n",
       "73202             2            1                  0            0.013889   \n",
       "6862              0            0                  2            0.014458   \n",
       "\n",
       "        diag_1_ord  diag_2_ord  diag_3_ord  \n",
       "64497            6           2           0  \n",
       "92020            0           0           0  \n",
       "58939            3          10           2  \n",
       "50295            0           1           7  \n",
       "101228           2           3          10  \n",
       "...            ...         ...         ...  \n",
       "34324            0           8           0  \n",
       "99464            3          10          10  \n",
       "37345            0           0           2  \n",
       "73202            2           1          10  \n",
       "6862             4          10           4  \n",
       "\n",
       "[73507 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train - test - oot\n",
    "oot_pdf = data_sdf[(data_sdf['snapshot_date'] >= config[\"oot_start_date\"].date()) & (data_sdf['snapshot_date'] <= config[\"oot_end_date\"].date())]\n",
    "train_test_pdf = data_sdf[(data_sdf['snapshot_date'] >= config[\"train_test_start_date\"].date()) & (data_sdf['snapshot_date'] <= config[\"train_test_end_date\"].date())]\n",
    "\n",
    "feature_cols = [c for c in train_test_pdf.columns if c not in [\"encounter_id\", \"snapshot_date\", \"label\"]]\n",
    "\n",
    "X_oot = oot_pdf[feature_cols]\n",
    "y_oot = oot_pdf[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_test_pdf[feature_cols], train_test_pdf[\"label\"], \n",
    "    test_size= 1 - config[\"train_test_ratio\"],\n",
    "    random_state=88,     # Ensures reproducibility\n",
    "    shuffle=True,        # Shuffle the data before splitting\n",
    "    stratify=train_test_pdf[\"label\"]           # Stratify based on the label column\n",
    ")\n",
    "\n",
    "\n",
    "print('X_train', X_train.shape[0])\n",
    "print('X_test', X_test.shape[0])\n",
    "print('X_oot', X_oot.shape[0])\n",
    "print('y_train', y_train.shape[0], round(y_train.mean(),2))\n",
    "print('y_test', y_test.shape[0], round(y_test.mean(),2))\n",
    "print('y_oot', y_oot.shape[0], round(y_oot.mean(),2))\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58592ceb-2acb-4e71-91bd-119719e90eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_processed 73507\n",
      "X_test_processed 18377\n",
      "X_oot_processed 9882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.072197</td>\n",
       "      <td>-0.745774</td>\n",
       "      <td>0.406163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.551448</td>\n",
       "      <td>-0.745774</td>\n",
       "      <td>0.445668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.154182</td>\n",
       "      <td>-0.745774</td>\n",
       "      <td>0.136850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.551448</td>\n",
       "      <td>-0.745774</td>\n",
       "      <td>-0.082650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.092349</td>\n",
       "      <td>0.701293</td>\n",
       "      <td>-0.591680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73502</th>\n",
       "      <td>0.971370</td>\n",
       "      <td>0.701293</td>\n",
       "      <td>-0.285698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73503</th>\n",
       "      <td>0.551448</td>\n",
       "      <td>-0.745774</td>\n",
       "      <td>1.304115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73504</th>\n",
       "      <td>-0.485948</td>\n",
       "      <td>-0.745774</td>\n",
       "      <td>-0.402097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73505</th>\n",
       "      <td>-1.154182</td>\n",
       "      <td>-0.745774</td>\n",
       "      <td>-0.589977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73506</th>\n",
       "      <td>-0.485948</td>\n",
       "      <td>0.701293</td>\n",
       "      <td>-0.581542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73507 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2    3    4    5    6    7    8    9    10  \\\n",
       "0      0.072197 -0.745774  0.406163  0.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0   \n",
       "1      0.551448 -0.745774  0.445668  0.0  1.0  0.0  0.0  0.0  2.0  1.0  0.0   \n",
       "2     -1.154182 -0.745774  0.136850  0.0  1.0  0.0  0.0  1.0  3.0  2.0  0.0   \n",
       "3      0.551448 -0.745774 -0.082650  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "4     -3.092349  0.701293 -0.591680  1.0  0.0  0.0  0.0  1.0  3.0  3.0  0.0   \n",
       "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "73502  0.971370  0.701293 -0.285698  0.0  1.0  0.0  0.0  0.0  3.0  2.0  0.0   \n",
       "73503  0.551448 -0.745774  1.304115  0.0  1.0  0.0  0.0  1.0  3.0  2.0  0.0   \n",
       "73504 -0.485948 -0.745774 -0.402097  0.0  1.0  0.0  0.0  1.0  1.0  3.0  0.0   \n",
       "73505 -1.154182 -0.745774 -0.589977  0.0  1.0  0.0  0.0  1.0  3.0  2.0  0.0   \n",
       "73506 -0.485948  0.701293 -0.581542  0.0  1.0  0.0  0.0  0.0  3.0  2.0  0.0   \n",
       "\n",
       "        11   12   13   14    15    16  \n",
       "0      0.0  2.0  1.0  6.0   2.0   0.0  \n",
       "1      0.0 -1.0  1.0  0.0   0.0   0.0  \n",
       "2      0.0  0.0  0.0  3.0  10.0   2.0  \n",
       "3      0.0  0.0  0.0  0.0   1.0   7.0  \n",
       "4      0.0  1.0  1.0  2.0   3.0  10.0  \n",
       "...    ...  ...  ...  ...   ...   ...  \n",
       "73502  1.0  0.0  1.0  0.0   8.0   0.0  \n",
       "73503  0.0  0.0  0.0  3.0  10.0  10.0  \n",
       "73504  0.0  0.0  0.0  0.0   0.0   2.0  \n",
       "73505  1.0  2.0  1.0  2.0   1.0  10.0  \n",
       "73506  0.0  0.0  0.0  4.0  10.0   4.0  \n",
       "\n",
       "[73507 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- Define a named function for log1p transformation ---\n",
    "def log1p_transform(x):\n",
    "    return np.log1p(x)\n",
    "\n",
    "\n",
    "\n",
    "numeric_cols = [\n",
    "    'age_midpoint','severity_x_visits', 'medication_density'\n",
    "]\n",
    "\n",
    "# Create a pipeline for numeric columns\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('log', FunctionTransformer(log1p_transform)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Apply to numeric columns, keep the rest as is\n",
    "scaler = ColumnTransformer(\n",
    "    transformers=[('num', numeric_pipeline, numeric_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "transformer_stdscaler = scaler.fit(X_train)\n",
    "X_train_processed = transformer_stdscaler.transform(X_train)\n",
    "X_test_processed = transformer_stdscaler.transform(X_test)\n",
    "X_oot_processed = transformer_stdscaler.transform(X_oot)\n",
    "\n",
    "print('X_train_processed', X_train_processed.shape[0])\n",
    "print('X_test_processed', X_test_processed.shape[0])\n",
    "print('X_oot_processed', X_oot_processed.shape[0])\n",
    "\n",
    "pd.DataFrame(X_train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f623d3-ea36-45b1-8c36-736c58b9a017",
   "metadata": {},
   "source": [
    "### Logistic Regression Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "178774fb-2f1b-473f-82c1-de22d63c1424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "Best parameters found:\n",
      "{'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Best cross-validation AUC score:  0.5834830273889623\n",
      "\n",
      "AUC Scores:\n",
      "Train AUC: 0.6131\n",
      "Test  AUC: 0.6100\n",
      "OOT   AUC: 0.6212\n",
      "\n",
      "GINI Scores:\n",
      "Train GINI: 0.2262\n",
      "Test  GINI: 0.2199\n",
      "OOT   GINI: 0.2424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "import pprint\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Define the Logistic Regression model\n",
    "# --------------------------------------------------------\n",
    "log_reg = LogisticRegression(\n",
    "    solver='liblinear',  # works well for small/medium datasets & L1/L2 penalty\n",
    "    random_state=88,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Define the hyperparameter search space\n",
    "# --------------------------------------------------------\n",
    "param_dist = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # inverse of regularization strength\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Create a scorer based on AUC\n",
    "# --------------------------------------------------------\n",
    "auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Randomized search with cross-validation\n",
    "# --------------------------------------------------------\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_distributions=param_dist,\n",
    "    scoring=auc_scorer,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=1  # avoid unicode error in Chinese path\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Fit the model on TRAIN data\n",
    "# --------------------------------------------------------\n",
    "random_search.fit(X_train_processed, y_train)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Show best parameters and cross-val AUC\n",
    "# --------------------------------------------------------\n",
    "print(\"\\nBest parameters found:\")\n",
    "pprint.pprint(random_search.best_params_)\n",
    "print(\"Best cross-validation AUC score: \", random_search.best_score_)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Evaluate best model on TRAIN / TEST / OOT\n",
    "# --------------------------------------------------------\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# TRAIN\n",
    "y_pred_train = best_model.predict_proba(X_train_processed)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "# TEST\n",
    "y_pred_test = best_model.predict_proba(X_test_processed)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "# OOT\n",
    "y_pred_oot = best_model.predict_proba(X_oot_processed)[:, 1]\n",
    "oot_auc = roc_auc_score(y_oot, y_pred_oot)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Print all AUC + GINI scores\n",
    "# --------------------------------------------------------\n",
    "print(\"\\nAUC Scores:\")\n",
    "print(f\"Train AUC: {train_auc:.4f}\")\n",
    "print(f\"Test  AUC: {test_auc:.4f}\")\n",
    "print(f\"OOT   AUC: {oot_auc:.4f}\")\n",
    "\n",
    "print(\"\\nGINI Scores:\")\n",
    "print(f\"Train GINI: {2*train_auc - 1:.4f}\")\n",
    "print(f\"Test  GINI: {2*test_auc - 1:.4f}\")\n",
    "print(f\"OOT   GINI: {2*oot_auc - 1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45460b64-8333-4194-a557-37b7a22a3e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Feature  Coefficient\n",
      "1                race_Caucasian     0.343430\n",
      "13           medication_density     0.223942\n",
      "6      admission_severity_score     0.088149\n",
      "3                 race_Hispanic     0.082303\n",
      "0          race_AfricanAmerican     0.062587\n",
      "4                     is_female     0.056068\n",
      "8          poor_glucose_control     0.026553\n",
      "2                    race_Asian     0.021499\n",
      "9                 metformin_ord     0.007195\n",
      "16                   diag_3_ord     0.006682\n",
      "15                   diag_2_ord     0.003081\n",
      "7   admission_source_risk_score    -0.000094\n",
      "12            severity_x_visits    -0.011885\n",
      "14                   diag_1_ord    -0.014703\n",
      "10                  insulin_ord    -0.044671\n",
      "11                  diabetesMed    -0.145071\n",
      "5                  age_midpoint    -0.171203\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': best_model.coef_[0]\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dcccb05-1c95-4b70-9376-4eeb64698a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dates': {'model_train_date': datetime.datetime(2009, 1, 1, 0, 0),\n",
      "                'model_train_date_str': '2009-01-01',\n",
      "                'oot_end_date': datetime.datetime(2008, 12, 31, 0, 0),\n",
      "                'oot_period_months': 12,\n",
      "                'oot_start_date': datetime.datetime(2008, 1, 1, 0, 0),\n",
      "                'train_test_end_date': datetime.datetime(2007, 12, 31, 0, 0),\n",
      "                'train_test_period_months': 108,\n",
      "                'train_test_ratio': 0.8,\n",
      "                'train_test_start_date': datetime.datetime(1999, 1, 1, 0, 0)},\n",
      " 'data_stats': {'X_oot': 9882,\n",
      "                'X_test': 18377,\n",
      "                'X_train': 73507,\n",
      "                'y_oot': np.float64(0.11),\n",
      "                'y_test': np.float64(0.11),\n",
      "                'y_train': np.float64(0.11)},\n",
      " 'hp_params': {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'},\n",
      " 'model': LogisticRegression(C=10, class_weight='balanced', max_iter=1000, penalty='l1',\n",
      "                   random_state=88, solver='liblinear'),\n",
      " 'model_version': 'diabetes_LRmodel_2009_01_01',\n",
      " 'preprocessing_transformers': {'stdscaler': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('num',\n",
      "                                 Pipeline(steps=[('log',\n",
      "                                                  FunctionTransformer(func=<function log1p_transform at 0x7f437b904040>)),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 ['age_midpoint', 'severity_x_visits',\n",
      "                                  'medication_density'])])},\n",
      " 'results': {'auc_oot': np.float64(0.6212081164112211),\n",
      "             'auc_test': np.float64(0.609970584701998),\n",
      "             'auc_train': np.float64(0.6130807451190775),\n",
      "             'gini_oot': np.float64(0.242),\n",
      "             'gini_test': np.float64(0.22),\n",
      "             'gini_train': np.float64(0.226)}}\n",
      "Model saved to model_bank/diabetes_LRmodel_2009_01_01.pkl\n"
     ]
    }
   ],
   "source": [
    "model_artefact = {}\n",
    "\n",
    "model_artefact['model'] = best_model\n",
    "model_artefact['model_version'] = \"diabetes_LRmodel_\"+config[\"model_train_date_str\"].replace('-','_')\n",
    "model_artefact['preprocessing_transformers'] = {}\n",
    "model_artefact['preprocessing_transformers']['stdscaler'] = transformer_stdscaler\n",
    "model_artefact['data_dates'] = config\n",
    "model_artefact['data_stats'] = {}\n",
    "model_artefact['data_stats']['X_train'] = X_train.shape[0]\n",
    "model_artefact['data_stats']['X_test'] = X_test.shape[0]\n",
    "model_artefact['data_stats']['X_oot'] = X_oot.shape[0]\n",
    "model_artefact['data_stats']['y_train'] = round(y_train.mean(),2)\n",
    "model_artefact['data_stats']['y_test'] = round(y_test.mean(),2)\n",
    "model_artefact['data_stats']['y_oot'] = round(y_oot.mean(),2)\n",
    "model_artefact['results'] = {}\n",
    "model_artefact['results']['auc_train'] = train_auc\n",
    "model_artefact['results']['auc_test'] = test_auc\n",
    "model_artefact['results']['auc_oot'] = oot_auc\n",
    "model_artefact['results']['gini_train'] = round(2*train_auc-1,3)\n",
    "model_artefact['results']['gini_test'] = round(2*test_auc-1,3)\n",
    "model_artefact['results']['gini_oot'] = round(2*oot_auc-1,3)\n",
    "model_artefact['hp_params'] = random_search.best_params_\n",
    "\n",
    "\n",
    "pprint.pprint(model_artefact)\n",
    "\n",
    "# create model_bank dir\n",
    "model_bank_directory = \"model_bank/\"\n",
    "\n",
    "if not os.path.exists(model_bank_directory):\n",
    "    os.makedirs(model_bank_directory)\n",
    "\n",
    "# Full path to the file\n",
    "file_path = os.path.join(model_bank_directory, model_artefact['model_version'] + '.pkl')\n",
    "\n",
    "# Write the model to a pickle file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_artefact, file)\n",
    "\n",
    "print(f\"Model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f53005-17b6-4c8e-b642-2811f1944d20",
   "metadata": {},
   "source": [
    "### Random Forrest Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab453240-e501-49d5-a307-f2e19385eae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Best parameters found:\n",
      "{'class_weight': 'balanced',\n",
      " 'max_depth': 5,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 10,\n",
      " 'n_estimators': 500}\n",
      "Best cross-validation AUC score:  0.5870934050828418\n",
      "\n",
      "AUC Scores:\n",
      "Train AUC: 0.6342\n",
      "Test  AUC: 0.6184\n",
      "OOT   AUC: 0.6276\n",
      "\n",
      "GINI Scores:\n",
      "Train GINI: 0.2684\n",
      "Test  GINI: 0.2369\n",
      "OOT   GINI: 0.2552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Define the Random Forest model\n",
    "# --------------------------------------------------------\n",
    "rf_model = RandomForestClassifier(\n",
    "    random_state=88,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Define the hyperparameter search space\n",
    "# --------------------------------------------------------\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Create a scorer based on AUC\n",
    "# --------------------------------------------------------\n",
    "auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Randomized search with cross-validation\n",
    "# --------------------------------------------------------\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=param_dist,\n",
    "    scoring=auc_scorer,\n",
    "    n_iter=15,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Fit the model on TRAIN data\n",
    "# --------------------------------------------------------\n",
    "random_search.fit(X_train_processed, y_train)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Show best parameters and cross-val AUC\n",
    "# --------------------------------------------------------\n",
    "print(\"\\nBest parameters found:\")\n",
    "pprint.pprint(random_search.best_params_)\n",
    "print(\"Best cross-validation AUC score: \", random_search.best_score_)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Evaluate best model on TRAIN / TEST / OOT\n",
    "# --------------------------------------------------------\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# TRAIN\n",
    "y_pred_train = best_model.predict_proba(X_train_processed)[:, 1]\n",
    "train_auc_rf = roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "# TEST\n",
    "y_pred_test = best_model.predict_proba(X_test_processed)[:, 1]\n",
    "test_auc_rf = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "# OOT\n",
    "y_pred_oot = best_model.predict_proba(X_oot_processed)[:, 1]\n",
    "oot_auc_rf = roc_auc_score(y_oot, y_pred_oot)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Print all AUC + GINI scores\n",
    "# --------------------------------------------------------\n",
    "print(\"\\nAUC Scores:\")\n",
    "print(f\"Train AUC: {train_auc_rf:.4f}\")\n",
    "print(f\"Test  AUC: {test_auc_rf:.4f}\")\n",
    "print(f\"OOT   AUC: {oot_auc_rf:.4f}\")\n",
    "\n",
    "print(\"\\nGINI Scores:\")\n",
    "print(f\"Train GINI: {2*train_auc_rf - 1:.4f}\")\n",
    "print(f\"Test  GINI: {2*test_auc_rf - 1:.4f}\")\n",
    "print(f\"OOT   GINI: {2*oot_auc_rf - 1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30923b3d-9af3-4e71-826f-ad0085218daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Features by Importance:\n",
      "                        Feature  Importance\n",
      "1                race_Caucasian    0.677515\n",
      "0          race_AfricanAmerican    0.097820\n",
      "2                    race_Asian    0.088564\n",
      "14                   diag_1_ord    0.035474\n",
      "13           medication_density    0.019301\n",
      "16                   diag_3_ord    0.019141\n",
      "12            severity_x_visits    0.016108\n",
      "8          poor_glucose_control    0.011159\n",
      "11                  diabetesMed    0.010000\n",
      "15                   diag_2_ord    0.007733\n",
      "9                 metformin_ord    0.006787\n",
      "10                  insulin_ord    0.002630\n",
      "5                  age_midpoint    0.002137\n",
      "6      admission_severity_score    0.001924\n",
      "7   admission_source_risk_score    0.001374\n",
      "3                 race_Hispanic    0.001357\n",
      "4                     is_female    0.000976\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Feature Importance\n",
    "# --------------------------------------------------------\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop Features by Importance:\")\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "443ecc77-30b3-432e-b0f0-901c8d3d6fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dates': {'model_train_date': datetime.datetime(2009, 1, 1, 0, 0),\n",
      "                'model_train_date_str': '2009-01-01',\n",
      "                'oot_end_date': datetime.datetime(2008, 12, 31, 0, 0),\n",
      "                'oot_period_months': 12,\n",
      "                'oot_start_date': datetime.datetime(2008, 1, 1, 0, 0),\n",
      "                'train_test_end_date': datetime.datetime(2007, 12, 31, 0, 0),\n",
      "                'train_test_period_months': 108,\n",
      "                'train_test_ratio': 0.8,\n",
      "                'train_test_start_date': datetime.datetime(1999, 1, 1, 0, 0)},\n",
      " 'data_stats': {'X_oot': 9882,\n",
      "                'X_test': 18377,\n",
      "                'X_train': 73507,\n",
      "                'y_oot': np.float64(0.11),\n",
      "                'y_test': np.float64(0.11),\n",
      "                'y_train': np.float64(0.11)},\n",
      " 'hp_params': {'class_weight': 'balanced',\n",
      "               'max_depth': 5,\n",
      "               'max_features': None,\n",
      "               'min_samples_leaf': 1,\n",
      "               'min_samples_split': 10,\n",
      "               'n_estimators': 500},\n",
      " 'model': RandomForestClassifier(class_weight='balanced', max_depth=5, max_features=None,\n",
      "                       min_samples_split=10, n_estimators=500, n_jobs=-1,\n",
      "                       random_state=88),\n",
      " 'model_version': 'diabetes_RFmodel_2009_01_01',\n",
      " 'preprocessing_transformers': {'stdscaler': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('num',\n",
      "                                 Pipeline(steps=[('log',\n",
      "                                                  FunctionTransformer(func=<function log1p_transform at 0x7f437b904040>)),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 ['age_midpoint', 'severity_x_visits',\n",
      "                                  'medication_density'])])},\n",
      " 'results': {'auc_oot': np.float64(0.627624230949337),\n",
      "             'auc_test': np.float64(0.6184444297596408),\n",
      "             'auc_train': np.float64(0.6341905585606419),\n",
      "             'gini_oot': np.float64(0.255),\n",
      "             'gini_test': np.float64(0.237),\n",
      "             'gini_train': np.float64(0.268)}}\n",
      "Model saved to model_bank/diabetes_RFmodel_2009_01_01.pkl\n"
     ]
    }
   ],
   "source": [
    "model_artefact = {}\n",
    "\n",
    "model_artefact['model'] = best_model\n",
    "model_artefact['model_version'] = \"diabetes_RFmodel_\"+config[\"model_train_date_str\"].replace('-','_')\n",
    "model_artefact['preprocessing_transformers'] = {}\n",
    "model_artefact['preprocessing_transformers']['stdscaler'] = transformer_stdscaler\n",
    "model_artefact['data_dates'] = config\n",
    "model_artefact['data_stats'] = {}\n",
    "model_artefact['data_stats']['X_train'] = X_train.shape[0]\n",
    "model_artefact['data_stats']['X_test'] = X_test.shape[0]\n",
    "model_artefact['data_stats']['X_oot'] = X_oot.shape[0]\n",
    "model_artefact['data_stats']['y_train'] = round(y_train.mean(),2)\n",
    "model_artefact['data_stats']['y_test'] = round(y_test.mean(),2)\n",
    "model_artefact['data_stats']['y_oot'] = round(y_oot.mean(),2)\n",
    "model_artefact['results'] = {}\n",
    "model_artefact['results']['auc_train'] = train_auc_rf\n",
    "model_artefact['results']['auc_test'] = test_auc_rf\n",
    "model_artefact['results']['auc_oot'] = oot_auc_rf\n",
    "model_artefact['results']['gini_train'] = round(2*train_auc_rf-1,3)\n",
    "model_artefact['results']['gini_test'] = round(2*test_auc_rf-1,3)\n",
    "model_artefact['results']['gini_oot'] = round(2*oot_auc_rf-1,3)\n",
    "model_artefact['hp_params'] = random_search.best_params_\n",
    "\n",
    "\n",
    "pprint.pprint(model_artefact)\n",
    "\n",
    "# create model_bank dir\n",
    "model_bank_directory = \"model_bank/\"\n",
    "\n",
    "if not os.path.exists(model_bank_directory):\n",
    "    os.makedirs(model_bank_directory)\n",
    "\n",
    "# Full path to the file\n",
    "file_path = os.path.join(model_bank_directory, model_artefact['model_version'] + '.pkl')\n",
    "\n",
    "# Write the model to a pickle file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_artefact, file)\n",
    "\n",
    "print(f\"Model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25100c7",
   "metadata": {},
   "source": [
    "### XGBoost Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85656b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=1, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, scale_pos_weight=8, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, scale_pos_weight=8, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, scale_pos_weight=8, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=1, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=300, scale_pos_weight=8, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=300, scale_pos_weight=3, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=300, scale_pos_weight=3, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=300, scale_pos_weight=3, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=8, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=8, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=8, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=8, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=8, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=8, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=200, scale_pos_weight=1, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=200, scale_pos_weight=1, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=200, scale_pos_weight=1, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=5, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, scale_pos_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.9; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=100, scale_pos_weight=1, subsample=0.9; total time=   0.3s\n",
      "\n",
      "XGBoost best params:\n",
      "{'colsample_bytree': 0.8,\n",
      " 'gamma': 0.3,\n",
      " 'learning_rate': 0.05,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3,\n",
      " 'n_estimators': 200,\n",
      " 'scale_pos_weight': 8,\n",
      " 'subsample': 0.8}\n",
      "CV AUC: 0.5892\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'scale_pos_weight': [1, 3, 5, 8],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    random_state=42,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=xgb_params,\n",
    "    scoring=auc_scorer,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=1  # avoid unicode error in Chinese path\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"\\nXGBoost best params:\")\n",
    "pprint.pprint(xgb_search.best_params_)\n",
    "print(f\"CV AUC: {xgb_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8173ab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "XGBoost Performance\n",
      "==================================================\n",
      "\n",
      "AUC:\n",
      "  Train: 0.6941\n",
      "  Test:  0.6185\n",
      "  OOT:   0.6310\n",
      "\n",
      "GINI:\n",
      "  Train: 0.3883\n",
      "  Test:  0.2371\n",
      "  OOT:   0.2620\n",
      "\n",
      "PR-AUC (better for imbalanced):\n",
      "  Test: 0.1727\n",
      "  OOT:  0.1909\n"
     ]
    }
   ],
   "source": [
    "xgb_best = xgb_search.best_estimator_\n",
    "\n",
    "y_pred_train_xgb = xgb_best.predict_proba(X_train_processed)[:, 1]\n",
    "y_pred_test_xgb = xgb_best.predict_proba(X_test_processed)[:, 1]\n",
    "y_pred_oot_xgb = xgb_best.predict_proba(X_oot_processed)[:, 1]\n",
    "\n",
    "xgb_train_auc = roc_auc_score(y_train, y_pred_train_xgb)\n",
    "xgb_test_auc = roc_auc_score(y_test, y_pred_test_xgb)\n",
    "xgb_oot_auc = roc_auc_score(y_oot, y_pred_oot_xgb)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"XGBoost Performance\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nAUC:\")\n",
    "print(f\"  Train: {xgb_train_auc:.4f}\")\n",
    "print(f\"  Test:  {xgb_test_auc:.4f}\")\n",
    "print(f\"  OOT:   {xgb_oot_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nGINI:\")\n",
    "print(f\"  Train: {2*xgb_train_auc - 1:.4f}\")\n",
    "print(f\"  Test:  {2*xgb_test_auc - 1:.4f}\")\n",
    "print(f\"  OOT:   {2*xgb_oot_auc - 1:.4f}\")\n",
    "\n",
    "# additional metrics\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "pr_auc_test = average_precision_score(y_test, y_pred_test_xgb)\n",
    "pr_auc_oot = average_precision_score(y_oot, y_pred_oot_xgb)\n",
    "\n",
    "print(f\"\\nPR-AUC (better for imbalanced):\")\n",
    "print(f\"  Test: {pr_auc_test:.4f}\")\n",
    "print(f\"  OOT:  {pr_auc_oot:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b6dfe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Features:\n",
      "                    feature  importance\n",
      "             race_Caucasian    0.186903\n",
      "         medication_density    0.069659\n",
      "       race_AfricanAmerican    0.062174\n",
      "                 diag_1_ord    0.054181\n",
      "                diabetesMed    0.054118\n",
      "                 race_Asian    0.053167\n",
      "          severity_x_visits    0.052983\n",
      "                  is_female    0.052649\n",
      "               age_midpoint    0.052391\n",
      "   admission_severity_score    0.049589\n",
      "       poor_glucose_control    0.048804\n",
      "              metformin_ord    0.047540\n",
      "                 diag_3_ord    0.047512\n",
      "                 diag_2_ord    0.046930\n",
      "                insulin_ord    0.046357\n",
      "              race_Hispanic    0.037544\n",
      "admission_source_risk_score    0.037499\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature importance\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': xgb_best.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Features:\")\n",
    "print(xgb_importance.head(20).to_string(index=False))\n",
    "\n",
    "# plot top features\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_n = 20\n",
    "xgb_importance.head(top_n).plot(x='feature', y='importance', kind='barh', ax=ax)\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title(f'Top {top_n} Features - XGBoost')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d260e82b-ff46-4953-a855-ae1cd2ae616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dates': {'model_train_date': datetime.datetime(2009, 1, 1, 0, 0),\n",
      "                'model_train_date_str': '2009-01-01',\n",
      "                'oot_end_date': datetime.datetime(2008, 12, 31, 0, 0),\n",
      "                'oot_period_months': 12,\n",
      "                'oot_start_date': datetime.datetime(2008, 1, 1, 0, 0),\n",
      "                'train_test_end_date': datetime.datetime(2007, 12, 31, 0, 0),\n",
      "                'train_test_period_months': 108,\n",
      "                'train_test_ratio': 0.8,\n",
      "                'train_test_start_date': datetime.datetime(1999, 1, 1, 0, 0)},\n",
      " 'data_stats': {'X_oot': 9882,\n",
      "                'X_test': 18377,\n",
      "                'X_train': 73507,\n",
      "                'y_oot': np.float64(0.11),\n",
      "                'y_test': np.float64(0.11),\n",
      "                'y_train': np.float64(0.11)},\n",
      " 'hp_params': {'colsample_bytree': 0.8,\n",
      "               'gamma': 0.3,\n",
      "               'learning_rate': 0.05,\n",
      "               'max_depth': 5,\n",
      "               'min_child_weight': 3,\n",
      "               'n_estimators': 200,\n",
      "               'scale_pos_weight': 8,\n",
      "               'subsample': 0.8},\n",
      " 'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
      "              feature_weights=None, gamma=0.3, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=3, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
      "              n_jobs=None, num_parallel_tree=None, ...),\n",
      " 'model_version': 'diabetes_XGBoostmodel_2009_01_01',\n",
      " 'preprocessing_transformers': {'stdscaler': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('num',\n",
      "                                 Pipeline(steps=[('log',\n",
      "                                                  FunctionTransformer(func=<function log1p_transform at 0x7f437b904040>)),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 ['age_midpoint', 'severity_x_visits',\n",
      "                                  'medication_density'])])},\n",
      " 'results': {'auc_oot': np.float64(0.6309878402092174),\n",
      "             'auc_test': np.float64(0.6185420408074336),\n",
      "             'auc_train': np.float64(0.694145676535719),\n",
      "             'gini_oot': np.float64(0.262),\n",
      "             'gini_test': np.float64(0.237),\n",
      "             'gini_train': np.float64(0.388)}}\n",
      "Model saved to model_bank/diabetes_XGBoostmodel_2009_01_01.pkl\n"
     ]
    }
   ],
   "source": [
    "model_artefact = {}\n",
    "\n",
    "model_artefact['model'] = xgb_best\n",
    "model_artefact['model_version'] = \"diabetes_XGBoostmodel_\"+config[\"model_train_date_str\"].replace('-','_')\n",
    "model_artefact['preprocessing_transformers'] = {}\n",
    "model_artefact['preprocessing_transformers']['stdscaler'] = transformer_stdscaler\n",
    "model_artefact['data_dates'] = config\n",
    "model_artefact['data_stats'] = {}\n",
    "model_artefact['data_stats']['X_train'] = X_train.shape[0]\n",
    "model_artefact['data_stats']['X_test'] = X_test.shape[0]\n",
    "model_artefact['data_stats']['X_oot'] = X_oot.shape[0]\n",
    "model_artefact['data_stats']['y_train'] = round(y_train.mean(),2)\n",
    "model_artefact['data_stats']['y_test'] = round(y_test.mean(),2)\n",
    "model_artefact['data_stats']['y_oot'] = round(y_oot.mean(),2)\n",
    "model_artefact['results'] = {}\n",
    "model_artefact['results']['auc_train'] = xgb_train_auc\n",
    "model_artefact['results']['auc_test'] = xgb_test_auc\n",
    "model_artefact['results']['auc_oot'] = xgb_oot_auc\n",
    "model_artefact['results']['gini_train'] = round(2*xgb_train_auc-1,3)\n",
    "model_artefact['results']['gini_test'] = round(2*xgb_test_auc-1,3)\n",
    "model_artefact['results']['gini_oot'] = round(2*xgb_oot_auc-1,3)\n",
    "model_artefact['hp_params'] = xgb_search.best_params_\n",
    "\n",
    "\n",
    "pprint.pprint(model_artefact)\n",
    "\n",
    "# create model_bank dir\n",
    "model_bank_directory = \"model_bank/\"\n",
    "\n",
    "if not os.path.exists(model_bank_directory):\n",
    "    os.makedirs(model_bank_directory)\n",
    "\n",
    "# Full path to the file\n",
    "file_path = os.path.join(model_bank_directory, model_artefact['model_version'] + '.pkl')\n",
    "\n",
    "# Write the model to a pickle file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_artefact, file)\n",
    "\n",
    "print(f\"Model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c704e",
   "metadata": {},
   "source": [
    "### LightGBM Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27cdae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, min_child_samples=10, n_estimators=100, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, min_child_samples=10, n_estimators=100, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, min_child_samples=10, n_estimators=100, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=5, subsample=1.0; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=5, subsample=1.0; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=5, subsample=1.0; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=3, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=1, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=3, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=1, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=3, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=3, min_child_samples=5, n_estimators=100, num_leaves=15, scale_pos_weight=5, subsample=0.9; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=3, min_child_samples=5, n_estimators=100, num_leaves=15, scale_pos_weight=5, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=3, min_child_samples=5, n_estimators=100, num_leaves=15, scale_pos_weight=5, subsample=0.9; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, min_child_samples=20, n_estimators=200, num_leaves=31, scale_pos_weight=3, subsample=0.9; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, min_child_samples=20, n_estimators=200, num_leaves=31, scale_pos_weight=3, subsample=0.9; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, min_child_samples=20, n_estimators=200, num_leaves=31, scale_pos_weight=3, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=5, min_child_samples=20, n_estimators=100, num_leaves=15, scale_pos_weight=8, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=5, min_child_samples=20, n_estimators=100, num_leaves=15, scale_pos_weight=8, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=5, min_child_samples=20, n_estimators=100, num_leaves=15, scale_pos_weight=8, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=-1, min_child_samples=10, n_estimators=100, num_leaves=15, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=-1, min_child_samples=10, n_estimators=100, num_leaves=15, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=-1, min_child_samples=10, n_estimators=100, num_leaves=15, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_samples=10, n_estimators=100, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_samples=10, n_estimators=100, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_samples=10, n_estimators=100, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=5, min_child_samples=5, n_estimators=200, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=5, min_child_samples=5, n_estimators=200, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=5, min_child_samples=5, n_estimators=200, num_leaves=63, scale_pos_weight=8, subsample=0.9; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=-1, min_child_samples=20, n_estimators=300, num_leaves=15, scale_pos_weight=5, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=-1, min_child_samples=20, n_estimators=300, num_leaves=15, scale_pos_weight=5, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=-1, min_child_samples=20, n_estimators=300, num_leaves=15, scale_pos_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=-1, min_child_samples=5, n_estimators=100, num_leaves=31, scale_pos_weight=8, subsample=1.0; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=-1, min_child_samples=5, n_estimators=100, num_leaves=31, scale_pos_weight=8, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=-1, min_child_samples=5, n_estimators=100, num_leaves=31, scale_pos_weight=8, subsample=1.0; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, min_child_samples=5, n_estimators=300, num_leaves=31, scale_pos_weight=8, subsample=1.0; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, min_child_samples=5, n_estimators=300, num_leaves=31, scale_pos_weight=8, subsample=1.0; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, min_child_samples=5, n_estimators=300, num_leaves=31, scale_pos_weight=8, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_samples=20, n_estimators=100, num_leaves=15, scale_pos_weight=5, subsample=0.8; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_samples=20, n_estimators=100, num_leaves=15, scale_pos_weight=5, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_samples=20, n_estimators=100, num_leaves=15, scale_pos_weight=5, subsample=0.8; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_samples=5, n_estimators=200, num_leaves=63, scale_pos_weight=3, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_samples=5, n_estimators=200, num_leaves=63, scale_pos_weight=3, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_samples=5, n_estimators=200, num_leaves=63, scale_pos_weight=3, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, min_child_samples=10, n_estimators=100, num_leaves=31, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, min_child_samples=10, n_estimators=100, num_leaves=31, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, min_child_samples=10, n_estimators=100, num_leaves=31, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=8, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=8, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_samples=10, n_estimators=300, num_leaves=63, scale_pos_weight=8, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, min_child_samples=10, n_estimators=200, num_leaves=15, scale_pos_weight=1, subsample=0.9; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, min_child_samples=10, n_estimators=200, num_leaves=15, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, min_child_samples=10, n_estimators=200, num_leaves=15, scale_pos_weight=1, subsample=0.9; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, min_child_samples=10, n_estimators=200, num_leaves=31, scale_pos_weight=8, subsample=0.8; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, min_child_samples=10, n_estimators=200, num_leaves=31, scale_pos_weight=8, subsample=0.8; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, min_child_samples=10, n_estimators=200, num_leaves=31, scale_pos_weight=8, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=3, min_child_samples=10, n_estimators=100, num_leaves=31, scale_pos_weight=5, subsample=0.9; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=3, min_child_samples=10, n_estimators=100, num_leaves=31, scale_pos_weight=5, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=3, min_child_samples=10, n_estimators=100, num_leaves=31, scale_pos_weight=5, subsample=0.9; total time=   0.1s\n",
      "\n",
      "LightGBM best params:\n",
      "{'colsample_bytree': 0.9,\n",
      " 'learning_rate': 0.05,\n",
      " 'max_depth': 5,\n",
      " 'min_child_samples': 20,\n",
      " 'n_estimators': 100,\n",
      " 'num_leaves': 15,\n",
      " 'scale_pos_weight': 8,\n",
      " 'subsample': 0.9}\n",
      "CV AUC: 0.5902\n"
     ]
    }
   ],
   "source": [
    "# pip install lightgbm if needed\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    \n",
    "    lgb_params = {\n",
    "        'num_leaves': [15, 31, 63],\n",
    "        'max_depth': [3, 5, 7, -1],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "        'min_child_samples': [5, 10, 20],\n",
    "        'scale_pos_weight': [1, 3, 5, 8]\n",
    "    }\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        random_state=42,\n",
    "        verbosity=-1\n",
    "    )\n",
    "    \n",
    "    lgb_search = RandomizedSearchCV(\n",
    "        estimator=lgb_model,\n",
    "        param_distributions=lgb_params,\n",
    "        scoring=auc_scorer,\n",
    "        n_iter=20,\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        n_jobs=1  # avoid unicode error in Chinese path\n",
    "    )\n",
    "    \n",
    "    lgb_search.fit(X_train_processed, y_train)\n",
    "    \n",
    "    print(\"\\nLightGBM best params:\")\n",
    "    pprint.pprint(lgb_search.best_params_)\n",
    "    print(f\"CV AUC: {lgb_search.best_score_:.4f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"LightGBM not installed, skipping...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4c00e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "LightGBM Performance\n",
      "==================================================\n",
      "\n",
      "AUC:\n",
      "  Train: 0.5120\n",
      "  Test:  0.5098\n",
      "  OOT:   0.5021\n",
      "\n",
      "GINI:\n",
      "  Train: 0.0240\n",
      "  Test:  0.0196\n",
      "  OOT:   0.0041\n"
     ]
    }
   ],
   "source": [
    "if 'lgb_search' in locals():\n",
    "    lgb_best = lgb_search.best_estimator_\n",
    "    \n",
    "    y_pred_train_lgb = lgb_best.predict_proba(X_train)[:, 1]\n",
    "    y_pred_test_lgb = lgb_best.predict_proba(X_test)[:, 1]\n",
    "    y_pred_oot_lgb = lgb_best.predict_proba(X_oot)[:, 1]\n",
    "    \n",
    "    lgb_train_auc = roc_auc_score(y_train, y_pred_train_lgb)\n",
    "    lgb_test_auc = roc_auc_score(y_test, y_pred_test_lgb)\n",
    "    lgb_oot_auc = roc_auc_score(y_oot, y_pred_oot_lgb)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LightGBM Performance\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nAUC:\")\n",
    "    print(f\"  Train: {lgb_train_auc:.4f}\")\n",
    "    print(f\"  Test:  {lgb_test_auc:.4f}\")\n",
    "    print(f\"  OOT:   {lgb_oot_auc:.4f}\")\n",
    "    \n",
    "    print(f\"\\nGINI:\")\n",
    "    print(f\"  Train: {2*lgb_train_auc - 1:.4f}\")\n",
    "    print(f\"  Test:  {2*lgb_test_auc - 1:.4f}\")\n",
    "    print(f\"  OOT:   {2*lgb_oot_auc - 1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff3ae344-1a0f-4ab4-91d1-23a595120ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dates': {'model_train_date': datetime.datetime(2009, 1, 1, 0, 0),\n",
      "                'model_train_date_str': '2009-01-01',\n",
      "                'oot_end_date': datetime.datetime(2008, 12, 31, 0, 0),\n",
      "                'oot_period_months': 12,\n",
      "                'oot_start_date': datetime.datetime(2008, 1, 1, 0, 0),\n",
      "                'train_test_end_date': datetime.datetime(2007, 12, 31, 0, 0),\n",
      "                'train_test_period_months': 108,\n",
      "                'train_test_ratio': 0.8,\n",
      "                'train_test_start_date': datetime.datetime(1999, 1, 1, 0, 0)},\n",
      " 'data_stats': {'X_oot': 9882,\n",
      "                'X_test': 18377,\n",
      "                'X_train': 73507,\n",
      "                'y_oot': np.float64(0.11),\n",
      "                'y_test': np.float64(0.11),\n",
      "                'y_train': np.float64(0.11)},\n",
      " 'hp_params': {'colsample_bytree': 0.9,\n",
      "               'learning_rate': 0.05,\n",
      "               'max_depth': 5,\n",
      "               'min_child_samples': 20,\n",
      "               'n_estimators': 100,\n",
      "               'num_leaves': 15,\n",
      "               'scale_pos_weight': 8,\n",
      "               'subsample': 0.9},\n",
      " 'model': LGBMClassifier(colsample_bytree=0.9, learning_rate=0.05, max_depth=5,\n",
      "               metric='auc', num_leaves=15, objective='binary', random_state=42,\n",
      "               scale_pos_weight=8, subsample=0.9, verbosity=-1),\n",
      " 'model_version': 'diabetes_LightBGMmodel_2009_01_01',\n",
      " 'preprocessing_transformers': {'stdscaler': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('num',\n",
      "                                 Pipeline(steps=[('log',\n",
      "                                                  FunctionTransformer(func=<function log1p_transform at 0x7f437b904040>)),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 ['age_midpoint', 'severity_x_visits',\n",
      "                                  'medication_density'])])},\n",
      " 'results': {'auc_oot': np.float64(0.502073418919335),\n",
      "             'auc_test': np.float64(0.5098066406398472),\n",
      "             'auc_train': np.float64(0.5119811138826494),\n",
      "             'gini_oot': np.float64(0.004),\n",
      "             'gini_test': np.float64(0.02),\n",
      "             'gini_train': np.float64(0.024)}}\n",
      "Model saved to model_bank/diabetes_LightBGMmodel_2009_01_01.pkl\n"
     ]
    }
   ],
   "source": [
    "model_artefact = {}\n",
    "\n",
    "model_artefact['model'] = lgb_best\n",
    "model_artefact['model_version'] = \"diabetes_LightBGMmodel_\"+config[\"model_train_date_str\"].replace('-','_')\n",
    "model_artefact['preprocessing_transformers'] = {}\n",
    "model_artefact['preprocessing_transformers']['stdscaler'] = transformer_stdscaler\n",
    "model_artefact['data_dates'] = config\n",
    "model_artefact['data_stats'] = {}\n",
    "model_artefact['data_stats']['X_train'] = X_train.shape[0]\n",
    "model_artefact['data_stats']['X_test'] = X_test.shape[0]\n",
    "model_artefact['data_stats']['X_oot'] = X_oot.shape[0]\n",
    "model_artefact['data_stats']['y_train'] = round(y_train.mean(),2)\n",
    "model_artefact['data_stats']['y_test'] = round(y_test.mean(),2)\n",
    "model_artefact['data_stats']['y_oot'] = round(y_oot.mean(),2)\n",
    "model_artefact['results'] = {}\n",
    "model_artefact['results']['auc_train'] = lgb_train_auc\n",
    "model_artefact['results']['auc_test'] = lgb_test_auc\n",
    "model_artefact['results']['auc_oot'] = lgb_oot_auc\n",
    "model_artefact['results']['gini_train'] = round(2*lgb_train_auc-1,3)\n",
    "model_artefact['results']['gini_test'] = round(2*lgb_test_auc-1,3)\n",
    "model_artefact['results']['gini_oot'] = round(2*lgb_oot_auc-1,3)\n",
    "model_artefact['hp_params'] = lgb_search.best_params_\n",
    "\n",
    "\n",
    "pprint.pprint(model_artefact)\n",
    "\n",
    "# create model_bank dir\n",
    "model_bank_directory = \"model_bank/\"\n",
    "\n",
    "if not os.path.exists(model_bank_directory):\n",
    "    os.makedirs(model_bank_directory)\n",
    "\n",
    "# Full path to the file\n",
    "file_path = os.path.join(model_bank_directory, model_artefact['model_version'] + '.pkl')\n",
    "\n",
    "# Write the model to a pickle file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_artefact, file)\n",
    "\n",
    "print(f\"Model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ef551-682b-40f1-ba8a-19c2249497db",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1790a56-2dee-4bd6-b148-de0d0a8f3aa2",
   "metadata": {},
   "source": [
    "### Soft Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e81fa77d-98c2-4361-9679-0ffb38a6301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC Scores:\n",
      "Train AUC: 0.6577\n",
      "Test  AUC: 0.6210\n",
      "OOT   AUC: 0.6334\n",
      "\n",
      "GINI Scores:\n",
      "Train GINI: 0.3153\n",
      "Test  GINI: 0.2420\n",
      "OOT   GINI: 0.2668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle, os, pprint\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Load your trained models\n",
    "# --------------------------------------------------------\n",
    "# Load the model from the pickle file\n",
    "XGB_model_version = \"model_bank/\"+\"diabetes_XGBoostmodel_\"+config[\"model_train_date_str\"].replace('-','_')+\".pkl\"\n",
    "LR_model_version = \"model_bank/\"+\"diabetes_LRmodel_\"+config[\"model_train_date_str\"].replace('-','_')+\".pkl\"\n",
    "RF_model_version = \"model_bank/\"+\"diabetes_RFmodel_\"+config[\"model_train_date_str\"].replace('-','_')+\".pkl\"\n",
    "with open(LR_model_version , 'rb') as file:\n",
    "    logreg_model = pickle.load(file)\n",
    "with open(XGB_model_version , 'rb') as file:\n",
    "    xgb_model = pickle.load(file)\n",
    "with open(RF_model_version , 'rb') as file:\n",
    "    rf_model = pickle.load(file)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Create a Voting Ensemble\n",
    "# --------------------------------------------------------\n",
    "voting_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('logreg', logreg_model['model']),\n",
    "        ('rf', rf_model['model']),\n",
    "        ('xgb', xgb_model['model'])\n",
    "    ],\n",
    "    voting='soft'  # 'soft' uses predicted probabilities\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "voting_ensemble.fit(X_train_processed, y_train)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Evaluate Ensemble Performance\n",
    "# --------------------------------------------------------\n",
    "y_pred_train = voting_ensemble.predict_proba(X_train_processed)[:, 1]\n",
    "y_pred_test = voting_ensemble.predict_proba(X_test_processed)[:, 1]\n",
    "y_pred_oot = voting_ensemble.predict_proba(X_oot_processed)[:, 1]\n",
    "\n",
    "train_auc_vot = roc_auc_score(y_train, y_pred_train)\n",
    "test_auc_vot = roc_auc_score(y_test, y_pred_test)\n",
    "oot_auc_vot = roc_auc_score(y_oot, y_pred_oot)\n",
    "\n",
    "print(\"\\nAUC Scores:\")\n",
    "print(f\"Train AUC: {train_auc_vot:.4f}\")\n",
    "print(f\"Test  AUC: {test_auc_vot:.4f}\")\n",
    "print(f\"OOT   AUC: {oot_auc_vot:.4f}\")\n",
    "\n",
    "print(\"\\nGINI Scores:\")\n",
    "print(f\"Train GINI: {2*train_auc_vot - 1:.4f}\")\n",
    "print(f\"Test  GINI: {2*test_auc_vot - 1:.4f}\")\n",
    "print(f\"OOT   GINI: {2*oot_auc_vot - 1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32d12634-289f-42cc-8163-cbdb406b2062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dates': {'model_train_date': datetime.datetime(2009, 1, 1, 0, 0),\n",
      "                'model_train_date_str': '2009-01-01',\n",
      "                'oot_end_date': datetime.datetime(2008, 12, 31, 0, 0),\n",
      "                'oot_period_months': 12,\n",
      "                'oot_start_date': datetime.datetime(2008, 1, 1, 0, 0),\n",
      "                'train_test_end_date': datetime.datetime(2007, 12, 31, 0, 0),\n",
      "                'train_test_period_months': 108,\n",
      "                'train_test_ratio': 0.8,\n",
      "                'train_test_start_date': datetime.datetime(1999, 1, 1, 0, 0)},\n",
      " 'data_stats': {'X_oot': 9882,\n",
      "                'X_test': 18377,\n",
      "                'X_train': 73507,\n",
      "                'y_oot': np.float64(0.11),\n",
      "                'y_test': np.float64(0.11),\n",
      "                'y_train': np.float64(0.11)},\n",
      " 'hp_params': {'base_models': ['LogisticRegression', 'RandomForest', 'XGBoost'],\n",
      "               'voting': 'soft'},\n",
      " 'model': VotingClassifier(estimators=[('logreg',\n",
      "                              LogisticRegression(C=10, class_weight='balanced',\n",
      "                                                 max_iter=1000, penalty='l1',\n",
      "                                                 random_state=88,\n",
      "                                                 solver='liblinear')),\n",
      "                             ('rf',\n",
      "                              RandomForestClassifier(class_weight='balanced',\n",
      "                                                     max_depth=5,\n",
      "                                                     max_features=None,\n",
      "                                                     min_samples_split=10,\n",
      "                                                     n_estimators=500,\n",
      "                                                     n_jobs=-1,\n",
      "                                                     random_state=88)),\n",
      "                             ('xgb',\n",
      "                              XGBClassifier(base_score=None, booster=None,...\n",
      "                                            feature_weights=None, gamma=0.3,\n",
      "                                            grow_policy=None,\n",
      "                                            importance_type=None,\n",
      "                                            interaction_constraints=None,\n",
      "                                            learning_rate=0.05, max_bin=None,\n",
      "                                            max_cat_threshold=None,\n",
      "                                            max_cat_to_onehot=None,\n",
      "                                            max_delta_step=None, max_depth=5,\n",
      "                                            max_leaves=None, min_child_weight=3,\n",
      "                                            missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            multi_strategy=None,\n",
      "                                            n_estimators=200, n_jobs=None,\n",
      "                                            num_parallel_tree=None, ...))],\n",
      "                 voting='soft'),\n",
      " 'model_version': 'diabetes_votingensemble_2009_01_01',\n",
      " 'preprocessing_transformers': {'stdscaler': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('num',\n",
      "                                 Pipeline(steps=[('log',\n",
      "                                                  FunctionTransformer(func=<function log1p_transform at 0x7f437b904040>)),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 ['age_midpoint', 'severity_x_visits',\n",
      "                                  'medication_density'])])},\n",
      " 'results': {'auc_oot': np.float64(0.633398592254483),\n",
      "             'auc_test': np.float64(0.6210182758168876),\n",
      "             'auc_train': np.float64(0.6576571052147528),\n",
      "             'gini_oot': np.float64(0.267),\n",
      "             'gini_test': np.float64(0.242),\n",
      "             'gini_train': np.float64(0.315)}}\n",
      "Voting ensemble model saved to model_bank/diabetes_votingensemble_2009_01_01.pkl\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Save Model Artefact\n",
    "# --------------------------------------------------------\n",
    "model_artefact = {}\n",
    "model_artefact['model'] = voting_ensemble\n",
    "model_artefact['model_version'] = \"diabetes_votingensemble_\" + config[\"model_train_date_str\"].replace('-', '_')\n",
    "model_artefact['preprocessing_transformers'] = {'stdscaler': transformer_stdscaler}\n",
    "model_artefact['data_dates'] = config\n",
    "model_artefact['data_stats'] = {\n",
    "    'X_train': X_train.shape[0],\n",
    "    'X_test': X_test.shape[0],\n",
    "    'X_oot': X_oot.shape[0],\n",
    "    'y_train': round(y_train.mean(), 2),\n",
    "    'y_test': round(y_test.mean(), 2),\n",
    "    'y_oot': round(y_oot.mean(), 2)\n",
    "}\n",
    "model_artefact['results'] = {\n",
    "    'auc_train': train_auc_vot,\n",
    "    'auc_test': test_auc_vot,\n",
    "    'auc_oot': oot_auc_vot,\n",
    "    'gini_train': round(2*train_auc_vot - 1, 3),\n",
    "    'gini_test': round(2*test_auc_vot - 1, 3),\n",
    "    'gini_oot': round(2*oot_auc_vot - 1, 3)\n",
    "}\n",
    "model_artefact['hp_params'] = {\n",
    "    'base_models': ['LogisticRegression', 'RandomForest', 'XGBoost'],\n",
    "    'voting': 'soft'\n",
    "}\n",
    "\n",
    "pprint.pprint(model_artefact)\n",
    "\n",
    "# Save\n",
    "model_bank_directory = \"model_bank/\"\n",
    "if not os.path.exists(model_bank_directory):\n",
    "    os.makedirs(model_bank_directory)\n",
    "\n",
    "file_path = os.path.join(model_bank_directory, model_artefact['model_version'] + '.pkl')\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_artefact, file)\n",
    "\n",
    "print(f\"Voting ensemble model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77627d-2fff-4c61-8c98-f647e79edc7a",
   "metadata": {},
   "source": [
    "### Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "780e974a-d3dc-4450-9f83-e62b65a4ee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC Scores:\n",
      "Train AUC: 0.6760\n",
      "Test  AUC: 0.6209\n",
      "OOT   AUC: 0.6334\n",
      "\n",
      "GINI Scores:\n",
      "Train GINI: 0.3520\n",
      "Test  GINI: 0.2418\n",
      "OOT   GINI: 0.2669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Load your trained models\n",
    "# --------------------------------------------------------\n",
    "# Load the model from the pickle file\n",
    "XGB_model_version = \"model_bank/\"+\"diabetes_XGBoostmodel_\"+config[\"model_train_date_str\"].replace('-','_')+\".pkl\"\n",
    "LR_model_version = \"model_bank/\"+\"diabetes_LRmodel_\"+config[\"model_train_date_str\"].replace('-','_')+\".pkl\"\n",
    "RF_model_version = \"model_bank/\"+\"diabetes_RFmodel_\"+config[\"model_train_date_str\"].replace('-','_')+\".pkl\"\n",
    "with open(LR_model_version , 'rb') as file:\n",
    "    logreg_model = pickle.load(file)\n",
    "with open(XGB_model_version , 'rb') as file:\n",
    "    xgb_model = pickle.load(file)\n",
    "with open(RF_model_version , 'rb') as file:\n",
    "    rf_model = pickle.load(file)\n",
    "\n",
    "# Define the stacking ensemble\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logreg', logreg_model[\"model\"]),\n",
    "        ('rf', rf_model[\"model\"]),\n",
    "        ('xgb', xgb_model[\"model\"])\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000),\n",
    "    cv=3,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "stacking_ensemble.fit(X_train_processed, y_train)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Evaluate Ensemble Performance\n",
    "# --------------------------------------------------------\n",
    "y_pred_train = stacking_ensemble.predict_proba(X_train_processed)[:, 1]\n",
    "y_pred_test = stacking_ensemble.predict_proba(X_test_processed)[:, 1]\n",
    "y_pred_oot = stacking_ensemble.predict_proba(X_oot_processed)[:, 1]\n",
    "\n",
    "train_auc_stk = roc_auc_score(y_train, y_pred_train)\n",
    "test_auc_stk = roc_auc_score(y_test, y_pred_test)\n",
    "oot_auc_stk = roc_auc_score(y_oot, y_pred_oot)\n",
    "\n",
    "print(\"\\nAUC Scores:\")\n",
    "print(f\"Train AUC: {train_auc_stk:.4f}\")\n",
    "print(f\"Test  AUC: {test_auc_stk:.4f}\")\n",
    "print(f\"OOT   AUC: {oot_auc_stk:.4f}\")\n",
    "\n",
    "print(\"\\nGINI Scores:\")\n",
    "print(f\"Train GINI: {2*train_auc_stk - 1:.4f}\")\n",
    "print(f\"Test  GINI: {2*test_auc_stk - 1:.4f}\")\n",
    "print(f\"OOT   GINI: {2*oot_auc_stk - 1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5470366a-9015-4517-b389-8e601ff9f417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dates': {'model_train_date': datetime.datetime(2009, 1, 1, 0, 0),\n",
      "                'model_train_date_str': '2009-01-01',\n",
      "                'oot_end_date': datetime.datetime(2008, 12, 31, 0, 0),\n",
      "                'oot_period_months': 12,\n",
      "                'oot_start_date': datetime.datetime(2008, 1, 1, 0, 0),\n",
      "                'train_test_end_date': datetime.datetime(2007, 12, 31, 0, 0),\n",
      "                'train_test_period_months': 108,\n",
      "                'train_test_ratio': 0.8,\n",
      "                'train_test_start_date': datetime.datetime(1999, 1, 1, 0, 0)},\n",
      " 'data_stats': {'X_oot': 9882,\n",
      "                'X_test': 18377,\n",
      "                'X_train': 73507,\n",
      "                'y_oot': np.float64(0.11),\n",
      "                'y_test': np.float64(0.11),\n",
      "                'y_train': np.float64(0.11)},\n",
      " 'hp_params': {'base_models': ['LogisticRegression', 'RandomForest', 'XGBoost'],\n",
      "               'final_estimator': 'LogisticRegression'},\n",
      " 'model': StackingClassifier(cv=3,\n",
      "                   estimators=[('logreg',\n",
      "                                LogisticRegression(C=10,\n",
      "                                                   class_weight='balanced',\n",
      "                                                   max_iter=1000, penalty='l1',\n",
      "                                                   random_state=88,\n",
      "                                                   solver='liblinear')),\n",
      "                               ('rf',\n",
      "                                RandomForestClassifier(class_weight='balanced',\n",
      "                                                       max_depth=5,\n",
      "                                                       max_features=None,\n",
      "                                                       min_samples_split=10,\n",
      "                                                       n_estimators=500,\n",
      "                                                       n_jobs=-1,\n",
      "                                                       random_state=88)),\n",
      "                               ('xgb',\n",
      "                                XGBClassifier(base_score=None, booste...\n",
      "                                              importance_type=None,\n",
      "                                              interaction_constraints=None,\n",
      "                                              learning_rate=0.05, max_bin=None,\n",
      "                                              max_cat_threshold=None,\n",
      "                                              max_cat_to_onehot=None,\n",
      "                                              max_delta_step=None, max_depth=5,\n",
      "                                              max_leaves=None,\n",
      "                                              min_child_weight=3, missing=nan,\n",
      "                                              monotone_constraints=None,\n",
      "                                              multi_strategy=None,\n",
      "                                              n_estimators=200, n_jobs=None,\n",
      "                                              num_parallel_tree=None, ...))],\n",
      "                   final_estimator=LogisticRegression(max_iter=1000)),\n",
      " 'model_version': 'diabetes_stackensemble_2009_01_01',\n",
      " 'preprocessing_transformers': {'stdscaler': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('num',\n",
      "                                 Pipeline(steps=[('log',\n",
      "                                                  FunctionTransformer(func=<function log1p_transform at 0x7f437b904040>)),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 ['age_midpoint', 'severity_x_visits',\n",
      "                                  'medication_density'])])},\n",
      " 'results': {'auc_oot': np.float64(0.6334453793767226),\n",
      "             'auc_test': np.float64(0.6209240017710353),\n",
      "             'auc_train': np.float64(0.6759895848272014),\n",
      "             'gini_oot': np.float64(0.267),\n",
      "             'gini_test': np.float64(0.242),\n",
      "             'gini_train': np.float64(0.352)}}\n",
      "Voting ensemble model saved to model_bank/diabetes_stackensemble_2009_01_01.pkl\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Save Model Artefact\n",
    "# --------------------------------------------------------\n",
    "model_artefact = {}\n",
    "model_artefact['model'] = stacking_ensemble\n",
    "model_artefact['model_version'] = \"diabetes_stackensemble_\" + config[\"model_train_date_str\"].replace('-', '_')\n",
    "model_artefact['preprocessing_transformers'] = {'stdscaler': transformer_stdscaler}\n",
    "model_artefact['data_dates'] = config\n",
    "model_artefact['data_stats'] = {\n",
    "    'X_train': X_train.shape[0],\n",
    "    'X_test': X_test.shape[0],\n",
    "    'X_oot': X_oot.shape[0],\n",
    "    'y_train': round(y_train.mean(), 2),\n",
    "    'y_test': round(y_test.mean(), 2),\n",
    "    'y_oot': round(y_oot.mean(), 2)\n",
    "}\n",
    "model_artefact['results'] = {\n",
    "    'auc_train': train_auc_stk,\n",
    "    'auc_test': test_auc_stk,\n",
    "    'auc_oot': oot_auc_stk,\n",
    "    'gini_train': round(2*train_auc_stk - 1, 3),\n",
    "    'gini_test': round(2*test_auc_stk - 1, 3),\n",
    "    'gini_oot': round(2*oot_auc_stk - 1, 3)\n",
    "}\n",
    "model_artefact['hp_params'] = {\n",
    "    'base_models': ['LogisticRegression', 'RandomForest', 'XGBoost'],\n",
    "    'final_estimator': 'LogisticRegression'\n",
    "}\n",
    "\n",
    "pprint.pprint(model_artefact)\n",
    "\n",
    "# Save\n",
    "model_bank_directory = \"model_bank/\"\n",
    "if not os.path.exists(model_bank_directory):\n",
    "    os.makedirs(model_bank_directory)\n",
    "\n",
    "file_path = os.path.join(model_bank_directory, model_artefact['model_version'] + '.pkl')\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_artefact, file)\n",
    "\n",
    "print(f\"Voting ensemble model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa2b8ce",
   "metadata": {},
   "source": [
    "### Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d42848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON\n",
      "======================================================================\n",
      "              Model  Train_AUC  Test_AUC  OOT_AUC  Train_GINI  Test_GINI  OOT_GINI\n",
      "Logistic Regression   0.613081  0.609971 0.621208    0.226161   0.219941  0.242416\n",
      "      Random Forest   0.634191  0.618444 0.627624    0.268381   0.236889  0.255248\n",
      "            XGBoost   0.694146  0.618542 0.630988    0.388291   0.237084  0.261976\n",
      "    Voting Ensemble   0.657657  0.621018 0.633399    0.315314   0.242037  0.266797\n",
      "  Stacking Ensemble   0.675990  0.620924 0.633445    0.351979   0.241848  0.266891\n",
      "           LightGBM   0.511981  0.509807 0.502073    0.023962   0.019613  0.004147\n",
      "\n",
      "Best model by OOT GINI: Stacking Ensemble\n",
      "OOT GINI: 0.2669\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression',\"Random Forest\", 'XGBoost', \"Voting Ensemble\", \"Stacking Ensemble\"],\n",
    "    'Train_AUC': [train_auc,train_auc_rf, xgb_train_auc,train_auc_vot,train_auc_stk],\n",
    "    'Test_AUC': [test_auc,test_auc_rf, xgb_test_auc, test_auc_vot, test_auc_stk],\n",
    "    'OOT_AUC': [oot_auc,oot_auc_rf, xgb_oot_auc, oot_auc_vot, oot_auc_stk],\n",
    "    'Train_GINI': [2*train_auc-1,2*train_auc_rf-1, 2*xgb_train_auc-1, 2*train_auc_vot-1, 2*train_auc_stk-1],\n",
    "    'Test_GINI': [2*test_auc-1, 2*test_auc_rf-1,2*xgb_test_auc-1, 2*test_auc_vot-1, 2*test_auc_stk-1],\n",
    "    'OOT_GINI': [2*oot_auc-1,2*oot_auc_rf-1 ,2*xgb_oot_auc-1, 2*oot_auc_vot-1, 2*oot_auc_stk-1]\n",
    "})\n",
    "\n",
    "if 'lgb_oot_auc' in locals():\n",
    "    comparison = pd.concat([comparison, pd.DataFrame({\n",
    "        'Model': ['LightGBM'],\n",
    "        'Train_AUC': [lgb_train_auc],\n",
    "        'Test_AUC': [lgb_test_auc],\n",
    "        'OOT_AUC': [lgb_oot_auc],\n",
    "        'Train_GINI': [2*lgb_train_auc-1],\n",
    "        'Test_GINI': [2*lgb_test_auc-1],\n",
    "        'OOT_GINI': [2*lgb_oot_auc-1]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# identify best model\n",
    "best_idx = comparison['OOT_GINI'].idxmax()\n",
    "print(f\"\\nBest model by OOT GINI: {comparison.loc[best_idx, 'Model']}\")\n",
    "print(f\"OOT GINI: {comparison.loc[best_idx, 'OOT_GINI']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573a3ee",
   "metadata": {},
   "source": [
    "### Drift Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af2bb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for distribution drift between train and OOT\n",
    "# from scipy.stats import ks_2samp\n",
    "\n",
    "# drift_results = []\n",
    "\n",
    "# for feat in feature_cols:\n",
    "#     if feat in X_train.columns and feat in X_oot.columns:\n",
    "#         train_vals = X_train[feat].dropna()\n",
    "#         oot_vals = X_oot[feat].dropna()\n",
    "        \n",
    "#         # KS test\n",
    "#         ks_stat, p_value = ks_2samp(train_vals, oot_vals)\n",
    "        \n",
    "#         # PSI calculation\n",
    "#         def calc_psi(expected, actual, bins=10):\n",
    "#             breakpoints = np.linspace(0, 100, bins+1)\n",
    "#             expected_percents = np.percentile(expected, breakpoints)\n",
    "            \n",
    "#             expected_counts = np.histogram(expected, bins=expected_percents)[0]\n",
    "#             actual_counts = np.histogram(actual, bins=expected_percents)[0]\n",
    "            \n",
    "#             expected_percents = expected_counts / len(expected)\n",
    "#             actual_percents = actual_counts / len(actual)\n",
    "            \n",
    "#             # avoid log(0)\n",
    "#             expected_percents = np.where(expected_percents == 0, 0.0001, expected_percents)\n",
    "#             actual_percents = np.where(actual_percents == 0, 0.0001, actual_percents)\n",
    "            \n",
    "#             psi = np.sum((actual_percents - expected_percents) * np.log(actual_percents / expected_percents))\n",
    "#             return psi\n",
    "        \n",
    "#         try:\n",
    "#             psi = calc_psi(train_vals, oot_vals)\n",
    "#         except:\n",
    "#             psi = np.nan\n",
    "        \n",
    "#         drift_results.append({\n",
    "#             'feature': feat,\n",
    "#             'ks_stat': ks_stat,\n",
    "#             'p_value': p_value,\n",
    "#             'psi': psi,\n",
    "#             'drift_detected': (p_value < 0.05) or (psi > 0.1)\n",
    "#         })\n",
    "\n",
    "# drift_df = pd.DataFrame(drift_results).sort_values('psi', ascending=False)\n",
    "\n",
    "# print(\"Features with Drift (PSI > 0.1 or KS p-value < 0.05):\")\n",
    "# print(drift_df[drift_df['drift_detected']].head(15).to_string(index=False))\n",
    "\n",
    "# drift_count = drift_df['drift_detected'].sum()\n",
    "# print(f\"\\nTotal features with drift: {drift_count} / {len(feature_cols)} ({drift_count/len(feature_cols)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf672ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prediction distribution drift\n",
    "# pred_train_dist = np.histogram(y_pred_train_xgb, bins=20, range=(0,1))[0] / len(y_pred_train_xgb)\n",
    "# pred_test_dist = np.histogram(y_pred_test_xgb, bins=20, range=(0,1))[0] / len(y_pred_test_xgb)\n",
    "# pred_oot_dist = np.histogram(y_pred_oot_xgb, bins=20, range=(0,1))[0] / len(y_pred_oot_xgb)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# axes[0].hist(y_pred_train_xgb, bins=30, alpha=0.7, edgecolor='black')\n",
    "# axes[0].set_title('Train Predictions')\n",
    "# axes[0].set_xlabel('Predicted Probability')\n",
    "# axes[0].axvline(y_pred_train_xgb.mean(), color='r', linestyle='--', label=f'mean: {y_pred_train_xgb.mean():.3f}')\n",
    "# axes[0].legend()\n",
    "\n",
    "# axes[1].hist(y_pred_test_xgb, bins=30, alpha=0.7, edgecolor='black')\n",
    "# axes[1].set_title('Test Predictions')\n",
    "# axes[1].set_xlabel('Predicted Probability')\n",
    "# axes[1].axvline(y_pred_test_xgb.mean(), color='r', linestyle='--', label=f'mean: {y_pred_test_xgb.mean():.3f}')\n",
    "# axes[1].legend()\n",
    "\n",
    "# axes[2].hist(y_pred_oot_xgb, bins=30, alpha=0.7, edgecolor='black')\n",
    "# axes[2].set_title('OOT Predictions')\n",
    "# axes[2].set_xlabel('Predicted Probability')\n",
    "# axes[2].axvline(y_pred_oot_xgb.mean(), color='r', linestyle='--', label=f'mean: {y_pred_oot_xgb.mean():.3f}')\n",
    "# axes[2].legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"\\nPrediction mean shift:\")\n",
    "# print(f\"  Train: {y_pred_train_xgb.mean():.4f}\")\n",
    "# print(f\"  Test:  {y_pred_test_xgb.mean():.4f}\")\n",
    "# print(f\"  OOT:   {y_pred_oot_xgb.mean():.4f}\")\n",
    "# print(f\"  Shift (Train→OOT): {abs(y_pred_oot_xgb.mean() - y_pred_train_xgb.mean()):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef714127",
   "metadata": {},
   "source": [
    "### Save Model and Artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88a0528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save best XGBoost model\n",
    "# model_filename = f'xgboost_model_{config[\"model_train_date_str\"]}.pkl'\n",
    "# with open(model_filename, 'wb') as f:\n",
    "#     pickle.dump(xgb_best, f)\n",
    "\n",
    "# print(f\"Model saved: {model_filename}\")\n",
    "\n",
    "# # save feature list\n",
    "# with open('feature_columns.json', 'w') as f:\n",
    "#     json.dump(feature_cols, f, indent=2)\n",
    "\n",
    "# # save model metadata\n",
    "# metadata = {\n",
    "#     'model_type': 'XGBoost',\n",
    "#     'train_date': config[\"model_train_date_str\"],\n",
    "#     'train_period': f'{config[\"train_test_start_date\"]} to {config[\"train_test_end_date\"]}',\n",
    "#     'oot_period': f'{config[\"oot_start_date\"]} to {config[\"oot_end_date\"]}',\n",
    "#     'n_features': len(feature_cols),\n",
    "#     'train_samples': len(X_train),\n",
    "#     'test_samples': len(X_test),\n",
    "#     'oot_samples': len(X_oot),\n",
    "#     'train_auc': float(xgb_train_auc),\n",
    "#     'test_auc': float(xgb_test_auc),\n",
    "#     'oot_auc': float(xgb_oot_auc),\n",
    "#     'train_gini': float(2*xgb_train_auc - 1),\n",
    "#     'test_gini': float(2*xgb_test_auc - 1),\n",
    "#     'oot_gini': float(2*xgb_oot_auc - 1),\n",
    "#     'best_params': xgb_search.best_params_\n",
    "# }\n",
    "\n",
    "# with open('model_metadata.json', 'w') as f:\n",
    "#     json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "# print(\"Metadata saved: model_metadata.json\")\n",
    "\n",
    "# # save drift report\n",
    "# drift_df.to_csv('drift_report.csv', index=False)\n",
    "# print(\"Drift report saved: drift_report.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77bc0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save model to model bank with versioning\n",
    "# import os\n",
    "# import pickle\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "\n",
    "# # check if model exists\n",
    "# if 'xgb_best' not in locals():\n",
    "#     raise ValueError(\"❌ xgb_best not found. Please run Cell 25 (XGBoost Training) first!\")\n",
    "\n",
    "# # create model bank directory\n",
    "# model_bank_dir = \"model_bank\"\n",
    "# os.makedirs(model_bank_dir, exist_ok=True)\n",
    "\n",
    "# # generate version timestamp\n",
    "# version_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# model_version = f\"v_{version_timestamp}\"\n",
    "\n",
    "# # create version subdirectory\n",
    "# version_dir = os.path.join(model_bank_dir, model_version)\n",
    "# os.makedirs(version_dir, exist_ok=True)\n",
    "\n",
    "# # save XGBoost model\n",
    "# model_path = os.path.join(version_dir, \"xgboost_model.pkl\")\n",
    "# with open(model_path, 'wb') as f:\n",
    "#     pickle.dump(xgb_best, f)\n",
    "\n",
    "# # save LightGBM model if available\n",
    "# if 'lgb_best' in locals():\n",
    "#     lgb_model_path = os.path.join(version_dir, \"lightgbm_model.pkl\")\n",
    "#     with open(lgb_model_path, 'wb') as f:\n",
    "#         pickle.dump(lgb_best, f)\n",
    "\n",
    "# # save feature columns\n",
    "# feature_path = os.path.join(version_dir, \"feature_columns.json\")\n",
    "# with open(feature_path, 'w') as f:\n",
    "#     json.dump(feature_cols, f, indent=2)\n",
    "\n",
    "# # save comprehensive model metadata\n",
    "# model_bank_metadata = {\n",
    "#     'version': model_version,\n",
    "#     'created_at': version_timestamp,\n",
    "#     'model_type': 'XGBoost',\n",
    "#     'training_config': {\n",
    "#         'train_date': config[\"model_train_date_str\"],\n",
    "#         'train_period_start': str(config[\"train_test_start_date\"]),\n",
    "#         'train_period_end': str(config[\"train_test_end_date\"]),\n",
    "#         'oot_period_start': str(config[\"oot_start_date\"]),\n",
    "#         'oot_period_end': str(config[\"oot_end_date\"]),\n",
    "#         'train_test_ratio': config[\"train_test_ratio\"]\n",
    "#     },\n",
    "#     'data_info': {\n",
    "#         'n_features': len(feature_cols),\n",
    "#         'train_samples': int(len(X_train)),\n",
    "#         'test_samples': int(len(X_test)),\n",
    "#         'oot_samples': int(len(X_oot)),\n",
    "#         'train_positive_rate': float(y_train.mean()),\n",
    "#         'test_positive_rate': float(y_test.mean()),\n",
    "#         'oot_positive_rate': float(y_oot.mean())\n",
    "#     },\n",
    "#     'performance': {\n",
    "#         'xgboost': {\n",
    "#             'train_auc': float(xgb_train_auc),\n",
    "#             'test_auc': float(xgb_test_auc),\n",
    "#             'oot_auc': float(xgb_oot_auc),\n",
    "#             'train_gini': float(2*xgb_train_auc - 1),\n",
    "#             'test_gini': float(2*xgb_test_auc - 1),\n",
    "#             'oot_gini': float(2*xgb_oot_auc - 1),\n",
    "#             'best_params': xgb_search.best_params_\n",
    "#         }\n",
    "#     },\n",
    "#     'feature_engineering': {\n",
    "#         'diagnosis_features': True,\n",
    "#         'high_risk_categories': ['circulatory', 'diabetes', 'injury'],\n",
    "#         'composite_features': ['severity_x_visits', 'medication_density']\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # add LightGBM performance if available\n",
    "# if 'lgb_oot_auc' in locals():\n",
    "#     model_bank_metadata['performance']['lightgbm'] = {\n",
    "#         'train_auc': float(lgb_train_auc),\n",
    "#         'test_auc': float(lgb_test_auc),\n",
    "#         'oot_auc': float(lgb_oot_auc),\n",
    "#         'train_gini': float(2*lgb_train_auc - 1),\n",
    "#         'test_gini': float(2*lgb_test_auc - 1),\n",
    "#         'oot_gini': float(2*lgb_oot_auc - 1),\n",
    "#         'best_params': lgb_search.best_params_\n",
    "#     }\n",
    "\n",
    "# metadata_path = os.path.join(version_dir, \"model_metadata.json\")\n",
    "# with open(metadata_path, 'w') as f:\n",
    "#     json.dump(model_bank_metadata, f, indent=2, default=str)\n",
    "\n",
    "# # save baseline statistics\n",
    "# baseline_path = os.path.join(version_dir, \"baseline_stats.json\")\n",
    "# with open(baseline_path, 'w') as f:\n",
    "#     json.dump({k: {kk: float(vv) for kk, vv in v.items()} for k, v in baseline_stats.items()}, f, indent=2)\n",
    "\n",
    "# # save drift report\n",
    "# drift_path = os.path.join(version_dir, \"drift_report.csv\")\n",
    "# drift_df.to_csv(drift_path, index=False)\n",
    "\n",
    "# # save monitoring thresholds (will be defined in next cell)\n",
    "# # thresholds_path = os.path.join(version_dir, \"monitoring_thresholds.json\")\n",
    "\n",
    "# # create model registry file (for tracking all versions)\n",
    "# registry_file = os.path.join(model_bank_dir, \"model_registry.json\")\n",
    "# if os.path.exists(registry_file):\n",
    "#     with open(registry_file, 'r') as f:\n",
    "#         registry = json.load(f)\n",
    "# else:\n",
    "#     registry = {'models': []}\n",
    "\n",
    "# # add current version to registry\n",
    "# registry['models'].append({\n",
    "#     'version': model_version,\n",
    "#     'created_at': version_timestamp,\n",
    "#     'model_type': 'XGBoost',\n",
    "#     'oot_gini': float(2*xgb_oot_auc - 1),\n",
    "#     'oot_auc': float(xgb_oot_auc),\n",
    "#     'n_features': len(feature_cols),\n",
    "#     'path': version_dir\n",
    "# })\n",
    "\n",
    "# # keep only latest 10 versions in registry\n",
    "# registry['models'] = sorted(registry['models'], key=lambda x: x['created_at'], reverse=True)[:10]\n",
    "\n",
    "# with open(registry_file, 'w') as f:\n",
    "#     json.dump(registry, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440183f",
   "metadata": {},
   "source": [
    "### Monitoring Thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26beb695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define monitoring thresholds for production\n",
    "# monitoring_thresholds = {\n",
    "#     'performance': {\n",
    "#         'min_oot_gini': float(2*xgb_oot_auc - 1) * 0.90,  # alert if drops below 90% of baseline\n",
    "#         'min_oot_auc': float(xgb_oot_auc) * 0.90\n",
    "#     },\n",
    "#     'drift': {\n",
    "#         'max_psi': 0.2,  # moderate drift\n",
    "#         'critical_psi': 0.5,  # severe drift\n",
    "#         'max_ks_stat': 0.15\n",
    "#     },\n",
    "#     'predictions': {\n",
    "#         'max_pred_shift': 0.05,  # max shift in mean prediction\n",
    "#         'min_pred_rate': float(y_pred_oot_xgb.mean()) * 0.80,\n",
    "#         'max_pred_rate': float(y_pred_oot_xgb.mean()) * 1.20\n",
    "#     },\n",
    "#     'data_quality': {\n",
    "#         'max_null_pct': 5.0,\n",
    "#         'min_records_per_month': 1000\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# with open('monitoring_thresholds.json', 'w') as f:\n",
    "#     json.dump(monitoring_thresholds, f, indent=2)\n",
    "\n",
    "# print(\"Monitoring Thresholds:\")\n",
    "# print(json.dumps(monitoring_thresholds, indent=2))\n",
    "\n",
    "# # check current status against thresholds\n",
    "# alerts = []\n",
    "\n",
    "# if (2*xgb_oot_auc - 1) < monitoring_thresholds['performance']['min_oot_gini']:\n",
    "#     alerts.append(\"⚠ OOT GINI below threshold\")\n",
    "\n",
    "# high_drift_features = drift_df[drift_df['psi'] > monitoring_thresholds['drift']['max_psi']]\n",
    "# if len(high_drift_features) > 0:\n",
    "#     alerts.append(f\"⚠ {len(high_drift_features)} features with high drift (PSI > 0.2)\")\n",
    "\n",
    "# pred_shift = abs(y_pred_oot_xgb.mean() - y_pred_train_xgb.mean())\n",
    "# if pred_shift > monitoring_thresholds['predictions']['max_pred_shift']:\n",
    "#     alerts.append(f\"⚠ Prediction distribution shifted by {pred_shift:.4f}\")\n",
    "\n",
    "# if len(alerts) > 0:\n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"ALERTS\")\n",
    "#     print(\"=\"*50)\n",
    "#     for alert in alerts:\n",
    "#         print(alert)\n",
    "# else:\n",
    "#     print(\"\\n✓ All monitoring checks passed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4906074b",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d48e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"TRAINING PIPELINE COMPLETE\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# print(f\"\\nModel: XGBoost\")\n",
    "# print(f\"Training period: {config['train_test_start_date'].date()} to {config['train_test_end_date'].date()}\")\n",
    "# print(f\"OOT period: {config['oot_start_date'].date()} to {config['oot_end_date'].date()}\")\n",
    "# print(f\"Features: {len(feature_cols)} (including {len([c for c in feature_cols if 'diag' in c])} diagnosis-related)\")\n",
    "\n",
    "# print(f\"\\nPerformance:\")\n",
    "# print(f\"  OOT GINI: {2*xgb_oot_auc - 1:.4f}\")\n",
    "# print(f\"  OOT AUC:  {xgb_oot_auc:.4f}\")\n",
    "# print(f\"  PR-AUC:   {pr_auc_oot:.4f}\")\n",
    "\n",
    "# print(f\"\\nArtifacts saved:\")\n",
    "# print(f\"  - {model_filename}\")\n",
    "# print(f\"  - feature_columns.json\")\n",
    "# print(f\"  - model_metadata.json\")\n",
    "# print(f\"  - baseline_stats.json\")\n",
    "# print(f\"  - drift_report.csv\")\n",
    "# print(f\"  - monitoring_thresholds.json\")\n",
    "\n",
    "# print(f\"\\nNext steps:\")\n",
    "# print(f\"  1. Review feature importance and drift analysis\")\n",
    "# print(f\"  2. Deploy model to inference API\")\n",
    "# print(f\"  3. Set up monitoring dashboard\")\n",
    "# print(f\"  4. Schedule monthly retraining\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
